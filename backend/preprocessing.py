import pandas as pd
import numpy as np
import os

def load_and_process_data(data_path='../data/Data.csv', price_path='../data/StockPrice.csv'):
    """
    Loads data, aligns timestamps, handles missing values, and generates lagged features.
    
    Args:
        data_path: Path to independent variable CSV
        price_path: Path to target variable CSV
        
    Returns:
        df: Processed DataFrame with features and target
    """
    # Load datasets
    # Explicitly handling whitespace or encoding issues if any, though inspection showed clean CSVs
    df_data = pd.read_csv(data_path, parse_dates=['Date'])
    df_price = pd.read_csv(price_path, parse_dates=['Date'])

    # Sort by Date ascending
    df_data = df_data.sort_values('Date').reset_index(drop=True)
    df_price = df_price.sort_values('Date').reset_index(drop=True)

    # Merge on Date
    # Inner join to ensure we have both data points
    df = pd.merge(df_price, df_data, on='Date', how='inner')

    # Handle missing values - Forward Fill as per requirements (assumption: past data persists)
    df = df.ffill()

    # Feature Engineering
    # Requirement: "Stock price movement is influenced only by the previous dayâ€™s change in data."
    # So we need to shift Data to get t-1 values relative to Price(t)
    
    # Lag 1: Data(t-1)
    df['Data_Lag1'] = df['Data'].shift(1)
    
    # Lag 2: Data(t-2) - needed for day-over-day change of the *lagged* data
    df['Data_Lag2'] = df['Data'].shift(2) # Effective t-2

    # Day-over-day change: Data(t-1) - Data(t-2)
    df['Data_Diff'] = df['Data_Lag1'] - df['Data_Lag2']

    # Percentage change
    # Handle division by zero if necessary, though unlikely with this data
    df['Data_Pct_Change'] = (df['Data_Diff'] / df['Data_Lag2']) * 100

    # Drop NaN values generated by shifting (first 2 rows will be NaN)
    df = df.dropna().reset_index(drop=True)

    return df

if __name__ == "__main__":
    # Test execution
    try:
        df = load_and_process_data()
        print("Data processed successfully.")
        print(f"Shape: {df.shape}")
        print("\nFirst 5 rows:")
        print(df.head())
        print("\nLast 5 rows:")
        print(df.tail())
        
        # Save a debug CSV to verify
        df.to_csv("debug_processed_data.csv", index=False)
        print("\nSaved debug_processed_data.csv")
    except Exception as e:
        print(f"Error during processing: {e}")
